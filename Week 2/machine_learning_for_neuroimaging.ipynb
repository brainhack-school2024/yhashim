{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning to predict age from rs-fmri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets fetch the data!\n",
    "from nilearn import datasets\n",
    "data = datasets.fetch_development_fmri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(data.func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the atlas for extracting features and an example subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "parcellations = datasets.fetch_atlas_basc_multiscale_2015(version='sym')\n",
    "atlas_filename = parcellations.scale064\n",
    "\n",
    "print('Atlas ROIs are located in nifti image (4D) at: %s' %\n",
    "       atlas_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "plotting.plot_roi(atlas_filename, draw_cross=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fmri_filenames = data.func[0]\n",
    "print(fmri_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn import image \n",
    "\n",
    "averaged_Img = image.mean_img(fmri_filenames)\n",
    "plotting.plot_stat_map(averaged_Img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract signals on a parcellation defined by labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "\n",
    "masker = NiftiLabelsMasker(labels_img=atlas_filename, \n",
    "                           standardize=True, \n",
    "                           memory='nilearn_cache', \n",
    "                           verbose=1)\n",
    "\n",
    "# Here we go from nifti files to the signal time series in a \n",
    "# numpy array. Note how we give confounds to be regressed out \n",
    "# during signal extraction\n",
    "conf = data.confounds[0]\n",
    "time_series = masker.fit_transform(fmri_filenames, confounds=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "conf_df = pandas.read_csv(conf,sep='\\t')\n",
    "conf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "conf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute and display a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
    "correlation_matrix.shape\n",
    "# Exercise 5\n",
    "# The numbers representing the shape of the connectivity matrix (64 x 64) represent the regions of interest (ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "rise": {
     "scroll": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Mask the main diagonal for visualization:\n",
    "np.fill_diagonal(correlation_matrix, 0)\n",
    "\n",
    "# The labels we have start with the background (0), hence we skip the\n",
    "# first label  \n",
    "plotting.plot_matrix(correlation_matrix, figure=(10, 8),   \n",
    "                     labels=range(time_series.shape[-1]),\n",
    "                     vmax=0.8, vmin=-0.8, reorder=False)\n",
    "\n",
    "# matrices are ordered for block-like representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Here is a really simple for loop\n",
    "\n",
    "for i in range(10):\n",
    "    print('the number is', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "container = []\n",
    "for i in range(10):\n",
    "    container.append(i)\n",
    "\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn import datasets\n",
    "\n",
    "# load atlas\n",
    "multiscale = datasets.fetch_atlas_basc_multiscale_2015()\n",
    "atlas_filename = multiscale.scale064\n",
    "\n",
    "# initialize masker (change verbosity)\n",
    "masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True, \n",
    "                           memory='nilearn_cache', verbose=0)\n",
    "\n",
    "# initialize correlation measure, set to vectorize\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation', vectorize=True,\n",
    "                                         discard_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "all_features = [] # here is where we will put the data (a container)\n",
    "\n",
    "for i,sub in enumerate(data.func):\n",
    "    # extract the timeseries from the ROIs in the atlas\n",
    "    time_series = masker.fit_transform(sub, confounds=data.confounds[i])\n",
    "    # create a region x region correlation matrix\n",
    "    correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
    "    # add to our container\n",
    "    all_features.append(correlation_matrix)\n",
    "    # keep track of status\n",
    "    print('finished %s of %s'%(i+1,len(data.func)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's save the data to disk\n",
    "import numpy as np\n",
    "\n",
    "#np.savez_compressed('MAIN_BASC064_subsamp_features',a = all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "feat_file = 'MAIN_BASC064_subsamp_features.npz'\n",
    "X_features = np.load(feat_file)['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_features.shape\n",
    "# Exercise 5\n",
    "# The features we are using in the model are the shape of the time series data and the connectivity matrix derives from fMRI data. \n",
    "# The numbers representing the feature matrix (155, 2016) are 155 samples (subjects or sessions) and 2016 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_features, aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('feature matrix')\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('subjects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Y (our target) and assess its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's load the phenotype data\n",
    "import pandas\n",
    "\n",
    "pheno = pandas.DataFrame(data.phenotypic)\n",
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y_age = pheno['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.distplot(y_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "age_class = pheno['AgeGroup']\n",
    "age_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the sample to training/validation with a 60/40 ratio, and \n",
    "# stratify by age class, and also shuffle the data.\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                                    X_features, # x\n",
    "                                                    y_age, # y\n",
    "                                                    test_size = 0.4, # 60%/40% split  \n",
    "                                                    shuffle = True, # shuffle dataset\n",
    "                                                                    # before splitting\n",
    "                                                    stratify = age_class,  # keep\n",
    "                                                                           # distribution\n",
    "                                                                           # of ageclass\n",
    "                                                                           # consistent\n",
    "                                                                           # betw. train\n",
    "                                                                           # & test sets.\n",
    "                                                    random_state = 123 # same shuffle each\n",
    "                                                                       # time\n",
    "                                                                       )\n",
    "\n",
    "# print the size of our training and test groups\n",
    "print('training:', len(X_train),\n",
    "     'testing:', len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(y_train,label='train')\n",
    "sns.distplot(y_val,label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your first model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "l_svr = SVR(kernel='linear') # define the model\n",
    "\n",
    "l_svr.fit(X_train, y_train) # fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# predict the training data based on the model\n",
    "y_pred = l_svr.predict(X_train) \n",
    "\n",
    "# caluclate the model accuracy\n",
    "acc = l_svr.score(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "print('accuracy (R2)', acc)\n",
    "\n",
    "sns.regplot(x=y_pred,y=y_train)\n",
    "plt.xlabel('Predicted Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the sample to training/test with a 75/25 ratio, and \n",
    "# stratify by age class, and also shuffle the data.\n",
    "\n",
    "age_class2 = pheno.loc[y_train.index,'AgeGroup']\n",
    "\n",
    "X_train2, X_test, y_train2, y_test = train_test_split(\n",
    "                                                    X_train, # x\n",
    "                                                    y_train, # y\n",
    "                                                    test_size = 0.25, # 75%/25% split  \n",
    "                                                    shuffle = True, # shuffle dataset\n",
    "                                                                    # before splitting\n",
    "                                                    stratify = age_class2,  # keep\n",
    "                                                                           # distribution\n",
    "                                                                           # of ageclass\n",
    "                                                                           # consistent\n",
    "                                                                           # betw. train\n",
    "                                                                           # & test sets.\n",
    "                                                    random_state = 123 # same shuffle each\n",
    "                                                                       # time\n",
    "                                                                       )\n",
    "\n",
    "# print the size of our training and test groups\n",
    "print('training:', len(X_train2),\n",
    "     'testing:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# fit model just to training data\n",
    "l_svr.fit(X_train2,y_train2)\n",
    "\n",
    "# predict the *test* data based on the model trained on X_train2\n",
    "y_pred = l_svr.predict(X_test) \n",
    "\n",
    "# caluclate the model accuracy\n",
    "acc = l_svr.score(X_test, y_test) \n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "print('accuracy (R2) = ', acc)\n",
    "print('MAE = ',mae)\n",
    "\n",
    "sns.regplot(x=y_pred,y=y_test)\n",
    "plt.xlabel('Predicted Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "\n",
    "# predict\n",
    "y_pred = cross_val_predict(l_svr, X_train, y_train, cv=10)\n",
    "# scores\n",
    "acc = cross_val_score(l_svr, X_train, y_train, cv=10)\n",
    "mae = cross_val_score(l_svr, X_train, y_train, cv=10, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('Fold {} -- Acc = {}, MAE = {}'.format(i, acc[i],-mae[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "overall_acc = r2_score(y_train, y_pred)\n",
    "overall_mae = mean_absolute_error(y_train,y_pred)\n",
    "print('R2:',overall_acc)\n",
    "print('MAE:',overall_mae)\n",
    "\n",
    "sns.regplot(x=y_pred, y=y_train)\n",
    "plt.xlabel('Predicted Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweak your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a log transformer function and log transform Y (age)\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "log_transformer = FunctionTransformer(func = np.log, validate=True)\n",
    "log_transformer.fit(y_train.values.reshape(-1,1))\n",
    "y_train_log = log_transformer.transform(y_train.values.reshape(-1,1))[:,0]\n",
    "\n",
    "sns.distplot(y_train_log)\n",
    "plt.title(\"Log-Transformed Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# re-intialize the model\n",
    "l_svr = SVR(kernel='linear') \n",
    "\n",
    "# predict\n",
    "y_pred = cross_val_predict(l_svr, X_train, y_train_log, cv=10)\n",
    "\n",
    "# scores\n",
    "acc = r2_score(y_train_log, y_pred)\n",
    "mae = mean_absolute_error(y_train_log,y_pred)\n",
    "\n",
    "print('R2:',acc)\n",
    "print('MAE:',mae)\n",
    "\n",
    "sns.regplot(x=y_pred, y=y_train_log)\n",
    "plt.xlabel('Predicted Log Age')\n",
    "plt.ylabel('Log Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "SVR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "C_range = 10. ** np.arange(-3, 8) # A range of different values for C\n",
    "\n",
    "train_scores, valid_scores = validation_curve(l_svr, X_train, y_train_log, \n",
    "                                              param_name= \"C\",\n",
    "                                              param_range = C_range,\n",
    "                                              cv=10,\n",
    "                                             scoring='neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# A bit of pandas magic to prepare the data for a seaborn plot\n",
    "\n",
    "tScores = pandas.DataFrame(train_scores).stack().reset_index()\n",
    "tScores.columns = ['C','Fold','Score']\n",
    "tScores.loc[:,'Type'] = ['Train' for x in range(len(tScores))]\n",
    "\n",
    "vScores = pandas.DataFrame(valid_scores).stack().reset_index()\n",
    "vScores.columns = ['C','Fold','Score']\n",
    "vScores.loc[:,'Type'] = ['Validate' for x in range(len(vScores))]\n",
    "\n",
    "ValCurves = pandas.concat([tScores,vScores]).reset_index(drop=True)\n",
    "ValCurves.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# And plot!\n",
    "\n",
    "g = sns.catplot(x='C',y='Score',hue='Type',data=ValCurves,kind='point')\n",
    "plt.xticks(range(10))\n",
    "g.set_xticklabels(C_range, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "C_range = 10. ** np.arange(-3, 8)\n",
    "epsilon_range = 10. ** np.arange(-3, 8)\n",
    "\n",
    "param_grid = dict(epsilon=epsilon_range, C=C_range)\n",
    "\n",
    "grid = GridSearchCV(l_svr, param_grid=param_grid, cv=10)\n",
    "\n",
    "grid.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(SVR(kernel='linear',\n",
    "                               C=grid.best_params_['C'],\n",
    "                               epsilon=grid.best_params_['epsilon'], \n",
    "                               gamma='auto'), \n",
    "                           X_train, y_train_log, cv=10)\n",
    "\n",
    "# scores\n",
    "acc = r2_score(y_train_log, y_pred)\n",
    "mae = mean_absolute_error(y_train_log,y_pred)\n",
    "\n",
    "print('R2:',acc)\n",
    "print('MAE:',mae)\n",
    "\n",
    "sns.regplot(x=y_pred, y=y_train_log)\n",
    "plt.xlabel('Predicted Log Age')\n",
    "plt.ylabel('Log Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a more complicated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "validation_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "degree_range = list(range(1,8)) # A range of different values for C\n",
    "\n",
    "train_scores, valid_scores = validation_curve(SVR(kernel='poly',\n",
    "                                                  gamma='scale'\n",
    "                                                 ), \n",
    "                                              X=X_train, y=y_train_log, \n",
    "                                              param_name= \"degree\",\n",
    "                                              param_range = degree_range,\n",
    "                                              cv=10,\n",
    "                                             scoring='neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# A bit of pandas magic to prepare the data for a seaborn plot\n",
    "\n",
    "tScores = pandas.DataFrame(train_scores).stack().reset_index()\n",
    "tScores.columns = ['Degree','Fold','Score']\n",
    "tScores.loc[:,'Type'] = ['Train' for x in range(len(tScores))]\n",
    "\n",
    "vScores = pandas.DataFrame(valid_scores).stack().reset_index()\n",
    "vScores.columns = ['Degree','Fold','Score']\n",
    "vScores.loc[:,'Type'] = ['Validate' for x in range(len(vScores))]\n",
    "\n",
    "ValCurves = pandas.concat([tScores,vScores]).reset_index(drop=True)\n",
    "ValCurves.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# And plot!\n",
    "\n",
    "# g = sns.catplot(x='Degree',y='Score',hue='Type',data=ValCurves,kind='point')\n",
    "# plt.xticks(range(7))\n",
    "# g.set_xticklabels(degree_range, rotation=90)\n",
    "\n",
    "g = sns.catplot(x='Degree', y='Score', hue='Type', data=ValCurves, kind='point')\n",
    "plt.xticks(range(len(degree_range)), degree_range)\n",
    "g.set_xticklabels(degree_range, rotation=90)\n",
    "plt.title('Validation Curve for Polynomial SVR')\n",
    "plt.ylabel('Negative Mean Squared Error')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.show()\n",
    "\n",
    "# Exercise 6\n",
    "# Increasing the complexity of the models, as shown by the polynomial degrees, can lead to overfitting where the train error decreases, but the validation error increases.\n",
    "# This indicates that the model is fitting the noise in the training data rather than the underlying pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # Build a tiny pipeline that does feature selection (top 20% of features), \n",
    "# # and then prediction with our linear svr model.\n",
    "# model = Pipeline([\n",
    "#     ('feature_selection',SelectPercentile(f_regression,percentile=20)),\n",
    "#     ('prediction', l_svr)\n",
    "#                  ])\n",
    "\n",
    "# Exercise 3\n",
    "from sklearn.decomposition import PCA\n",
    "model = Pipeline([\n",
    "    ('feature_selection',PCA(n_components=0.9)),\n",
    "    ('prediction', l_svr)\n",
    "                 ])\n",
    "\n",
    "y_pred = [] # a container to catch the predictions from each fold\n",
    "y_index = [] # just in case, the index for each prediction\n",
    "\n",
    "# # First we create 10 splits of the data\n",
    "# skf = KFold(n_splits=10, shuffle=True, random_state=123)\n",
    "\n",
    "# # For each split, assemble the train and test samples \n",
    "# for tr_ind, te_ind in skf.split(X_train):\n",
    "#     X_tr = X_train[tr_ind]\n",
    "#     y_tr = y_train_log[tr_ind]\n",
    "#     X_te = X_train[te_ind]\n",
    "#     y_index += list(te_ind) # store the index of samples to predict\n",
    "    \n",
    "#     # and run our pipeline \n",
    "#     model.fit(X_tr, y_tr) # fit the data to the model using our mini pipeline\n",
    "#     predictions = model.predict(X_te).tolist() # get the predictions for this fold\n",
    "#     y_pred += predictions # add them to the list of predictions\n",
    "\n",
    "# Exercise 4\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# For each split, assemble the train and test samples \n",
    "for tr_ind, te_ind in loo.split(X_train):\n",
    "    X_tr = X_train[tr_ind]\n",
    "    y_tr = y_train_log[tr_ind]\n",
    "    X_te = X_train[te_ind]\n",
    "    y_index += list(te_ind) # store the index of samples to predict\n",
    "    \n",
    "    # and run our pipeline \n",
    "    model.fit(X_tr, y_tr) # fit the data to the model using our mini pipeline\n",
    "    predictions = model.predict(X_te).tolist() # get the predictions for this fold\n",
    "    y_pred += predictions # add them to the list of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "acc = r2_score(y_train_log[y_index], y_pred)\n",
    "mae = mean_absolute_error(y_train_log[y_index],y_pred)\n",
    "\n",
    "print('R2:',acc)\n",
    "print('MAE:',mae)\n",
    "\n",
    "sns.regplot(x=np.array(y_pred), y=y_train_log[y_index])\n",
    "plt.xlabel('Predicted Log Age')\n",
    "plt.ylabel('Log Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can our model predict age in completely un-seen data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Notice how we use the Scaler that was fit to X_train and apply to X_test,\n",
    "# rather than creating a new Scaler for X_test\n",
    "y_val_log = log_transformer.transform(y_val.values.reshape(-1,1))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 6\n",
    "from sklearn.svm import LinearSVR\n",
    "l_svr = LinearSVR(C=1.0, max_iter=10000)  # The C parameter controls the regularization strength\n",
    "# l_svr = SVR(kernel='linear') # define the model\n",
    "l_svr.fit(X_train, y_train_log) # fit to training data\n",
    "y_pred = l_svr.predict(X_val) # classify age class using testing data\n",
    "acc = l_svr.score(X_val, y_val_log) # get accuracy (r2)\n",
    "mae = mean_absolute_error(y_val_log, y_pred) # get mae\n",
    "\n",
    "# print results\n",
    "print('accuracy (r2) =', acc)\n",
    "print('mae = ',mae)\n",
    "\n",
    "# plot results\n",
    "sns.regplot(x=y_pred, y=y_val_log)\n",
    "plt.xlabel('Predicted Log Age')\n",
    "plt.ylabel('Log Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# # Assignment\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # To store results of multiple splits\n",
    "# all_accuracies = []\n",
    "# all_maes = []\n",
    "\n",
    "# # Repeat the train-validation split 10 times\n",
    "# for i in range(10):\n",
    "#     # Create a new train-validation split\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(\n",
    "#         X_features, y_age, test_size=0.4, shuffle=True, stratify=age_class, random_state=i)\n",
    "    \n",
    "#     # Transform the target variable using the log transformation\n",
    "#     y_train_log = log_transformer.transform(y_train.values.reshape(-1,1))[:,0]\n",
    "#     y_val_log = log_transformer.transform(y_val.values.reshape(-1,1))[:,0]\n",
    "\n",
    "#     # Fit the model on the training data\n",
    "#     l_svr.fit(X_train, y_train_log)\n",
    "    \n",
    "#     # Predict the ages on the validation data\n",
    "#     y_pred = l_svr.predict(X_val)\n",
    "    \n",
    "#     # Calculate accuracy (R2 score) and mean absolute error (MAE)\n",
    "#     acc = l_svr.score(X_val, y_val_log)\n",
    "#     mae = mean_absolute_error(y_val_log, y_pred)\n",
    "    \n",
    "#     # Store the results\n",
    "#     all_accuracies.append(acc)\n",
    "#     all_maes.append(mae)\n",
    "    \n",
    "#     # Print the results for each split\n",
    "#     print(f'Split {i+1}: accuracy (R2) = {acc}, MAE = {mae}')\n",
    "\n",
    "# # Plot the range of predictions\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(data=[all_accuracies, all_maes], orient='h')\n",
    "# plt.yticks([0, 1], ['R2 Score', 'MAE'])\n",
    "# plt.title('Range of Predictions Across 10 Splits')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting model feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "l_svr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(range(l_svr.coef_.shape[-1]),l_svr.coef_[0])\n",
    "plt.title('feature importances')\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "correlation_measure.inverse_transform(l_svr.coef_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "feat_exp_matrix = correlation_measure.inverse_transform(l_svr.coef_)[0]\n",
    "\n",
    "plotting.plot_matrix(feat_exp_matrix, figure=(10, 8),  \n",
    "                     labels=range(feat_exp_matrix.shape[0]),\n",
    "                     reorder=False,\n",
    "                    tri='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "coords = plotting.find_parcellation_cut_coords(atlas_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plot_connectome(feat_exp_matrix, coords, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plot_connectome(feat_exp_matrix, coords, colorbar=True, edge_threshold=0.035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plotting.view_connectome(feat_exp_matrix, coords, edge_threshold='98%',\n",
    "                        edge_cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
